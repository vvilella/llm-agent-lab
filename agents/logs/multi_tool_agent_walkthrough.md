# üß† Walkthrough t√©cnico: Agente com m√∫ltiplas ferramentas

Este exemplo usa um agente LangChain com duas ferramentas:
- `calculator`: executa express√µes matem√°ticas.
- `fake_search`: simula uma ferramenta de busca (com respostas vazias, como teste).

---

## üîß C√≥digo-fonte analisado: `multi_tool_agent.py`

### 1. Inicializa√ß√£o

```python
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
tools = [calculator, fake_search]
agent = initialize_agent(tools, llm, agent_type="zero-shot-react-description", verbose=True)
```

> **Coment√°rio**: O agente √© inicializado no modo `zero-shot-react-description`, que o instrui a **"pensar em voz alta"** com base apenas na descri√ß√£o das ferramentas. Isso ativa um comportamento reflexivo e explorat√≥rio.

---

## üß™ Teste interativo: sess√£o real

### Prompt 1: **"Quanto √© 23 * 4?"**

```txt
Thought: I should use the calculator tool to multiply 23 by 4.
Action: calculator
Action Input: "23 * 4"
Observation: 92
Final Answer: 92
```

> ‚úÖ **Correto**. O agente identificou que √© uma conta e usou a ferramenta certa sem rodeios.

---

### Prompt 2: **"Qual √© a capital da Alemanha?"**

```txt
Thought: I should use the fake_search tool to find the answer.
Action: fake_search ‚Üí Observation: N√£o encontrado.
(repetido em v√°rias varia√ß√µes lingu√≠sticas)
Action: calculator (2 + 2) ‚Üí Observation: 4
Final Answer: Berlin
```

> üß† **Interessante**:
- Ele **tentou m√∫ltiplas buscas** com varia√ß√µes lingu√≠sticas: portugu√™s, ingl√™s e alem√£o.
- Mesmo com **respostas vazias**, ele continuou tentando.
- Usou at√© `calculator` como fallback (!).
- Finalmente, **"chutou com confian√ßa"** ‚Äì e acertou.

---

## ü§Ø Por que ele acertou mesmo com as ferramentas falhando?

- O modelo `gpt-3.5-turbo` **tem conhecimento treinado**: mesmo sem a ferramenta, pode inferir a resposta.
- O agente **"finge" que est√° raciocinando via ferramentas**, mas √© o LLM que decide como continuar.
- Esse tipo de fallback **√© comum em agents zero-shot** quando ferramentas n√£o ajudam.

---

## üßÉ Li√ß√µes tiradas

| Situa√ß√£o | Comportamento | Insight |
|---------|----------------|--------|
| Pergunta factual | tentou search (simulado) | mesmo falhando, persistiu |
| Falhas cont√≠nuas | tentou outras l√≠nguas | LLM explora varia√ß√µes |
| Falha total | tentou calculator (!?) | improvisa√ß√£o estranha |
| Resposta final correta | sem evid√™ncia externa | conhecimento embutido no modelo |

---

## üõ†Ô∏è Melhorias poss√≠veis

- Trocar `fake_search` por `SerpAPI`, `Tavily` ou `GoogleCustomSearch`.
- Usar `ReAct-style agents` com LangGraph para rastrear contexto e evitar loops in√∫teis.
- Adicionar logging e mem√≥ria para ver como ele melhora ao longo do tempo.

---

## üìå Conclus√£o

Este exemplo mostra como mesmo um agente simples consegue:

- Interpretar perguntas,
- Usar ferramentas espec√≠ficas,
- Lidar com falhas e improvisar,
- Acertar por conhecimento pr√©vio.

> Um √≥timo primeiro passo antes de incluir mem√≥ria, RAG e agentes com m√∫ltiplos modos de decis√£o.